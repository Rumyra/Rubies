<!DOCTYPE html>
<html lang="en">
<head>
  <!--char set (lang above)-->
  <meta charset="utf-8">

  <!--device/browser shizzle-->
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!--meta content-->
  <link rel="shortcut icon" href="favicon.ico" />
  
  <meta name="author" content="Ruth John (@rumyra)">
  <meta name="dcterms.rightsHolder" content="Ruth John for Rumyra Ltd, United Kingdom, 2015">
  <title>Rumyra's Interactive VJing</title>

  <link href="public/css/projection.css" rel="stylesheet" type="text/css">
  <script src="https://js.pusher.com/3.0/pusher.min.js"></script>
  <script src="d3/d3.min.js"></script>

  <style type="text/css">
  #screen {background: black;}
  </style>
  
</head>
<body class="projection">

<div id="screen">

  
</div>



<div id="pusher" data-key="{{PUSH_KEY}}"></div>
<script type="text/javascript" src="public/scripts/Gem.js"></script>
<script type="text/javascript">
var config = document.getElementById('pusher').dataset;
var pusher = new Pusher(config.key, {encrypted:true});

Pusher.channel_auth_endpoint = 'http://localhost:3000/pusher/auth';
pusher.connection.bind('state_change', function(states) {
    console.log("Pusher's current state is " + states.current);
});

// subscribe to channel
var channel = pusher.subscribe('private-rubies');

channel.bind('pusher:subscription_succeeded', function() {
  console.log('subscription succeeded');
});

// Generating and adding gems to screen
var screen = document.getElementById('screen');
// On user subscribe create ruby with id
channel.bind('client-audience_data', function(data) {
  console.log(data);
  // createGem(data.person, screen);
});
channel.bind('client-audience_joined', function(data) {
  createGem(data.person, screen);
});



// set up audio context
var audioContext = (window.AudioContext || window.webkitAudioContext);
// create audio class
if (audioContext) {
  // Web Audio API is available.
  var audioApi = new audioContext();
} else {
  // Web Audio API is not available. Ask the user to use a supported browser.
  alert("Oh nos! It appears your browser does not support the Web Audio API, please upgrade or use a different browser");
}
// set up getUserMedia
navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia;

// variables
var audioBuffer,
    analyserNode,
    frequencyData = new Uint8Array(1024);

// create an audio API analyser node and connect to source
function createAnalyserNode(audioSource) {
  analyserNode = audioApi.createAnalyser();
  analyserNode.fftSize = 2048;
  audioSource.connect(analyserNode);
}
// animate rotate
function changeRotateFreq(freqRange, svgId) {
  svgEl = document.getElementById(svgId);
  analyserNode.getByteFrequencyData(frequencyData);
  var freqIndex = 300;
  if (freqRange == 'low') {
    freqIndex = 80
  } else if (freqRange == 'mid') {
    freqIndex = 175
  }
  if (frequencyData[freqIndex] > 80) {
    svgId.style.transform = 'rotate('+(frequencyData[freqIndex]/10)+'deg)';  
  }
}
// animate flash

// animate size

// change colour

// high 600 - 250 mid 250 - 100 low 100 - 0
var rotateVal = 0, scaleVal = 0;
function animateSvgs() {
  requestAnimationFrame(animateSvgs);
  analyserNode.getByteFrequencyData(frequencyData);
  
  // Animation stuff--------------------------------
  var allRepeatedEls = document.getElementsByTagName('svg');
  var totalEls = allRepeatedEls.length;

  // Simple example of changing opacity & colour -> EDIT THIS!
  for (var i=0; i<totalEls; i++) {
    // if high freq flash
    if (frequencyData[350] > 80) {
      allRepeatedEls[i].children[0].style.fill = 'hsla(346, 100%, '+(frequencyData[350]/2)+'%, 1)'
    }
    

    // if mid freq rotate
    if (frequencyData[175] > 100) {
      rotateVal += frequencyData[175]/100;
    }

    // if low freq change size
    if (frequencyData[80] > 80) {
      scaleVal = frequencyData[80]/100;
    }
    allRepeatedEls[i].style.transform = 'rotate('+rotateVal+'deg) scale('+scaleVal+')';
  }
}


// getUserMedia success callback -> pipe audio stream into audio API
function gotStream(stream) {
    // Create an audio input from the stream.
    var audioSource = audioApi.createMediaStreamSource(stream);
    createAnalyserNode(audioSource);
    animateSvgs();
}

// pipe in analysing to getUserMedia
navigator.getUserMedia(
  {audio:true},
  gotStream,
  function(err) {
    console.log("The following error occured: " + err);
  } 
);


// var tempAr = [1,2,3,4,5,6,7];
// for (var i=0; i<tempAr.length; i++) {
//   createGem(screen);
// }

var allGems = document.getElementsByTagName('svg');
// console.log(allGems);

// set layout
var w = window.innerWidth;
var h = window.innerHeight;

var force = d3.layout.force()
.nodes(allGems).size(w,h).start();


</script>
</body>
</html>